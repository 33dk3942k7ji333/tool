{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics.pairwise import manhattan_distances, pairwise_distances, pairwise_distances_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Part', 'Reticle', 'Prev1Reticle', 'Tool', 'Prev1Tool', 'Prev2Tool',\n",
       "       'ChuckID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(\"./df_data.csv\")\n",
    "feat_list = df_data.columns\n",
    "feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493848, 73)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_list = []\n",
    "df_data_le = pd.DataFrame()\n",
    "for _feat in feat_list:\n",
    "    le = LabelEncoder()\n",
    "    df_data_le[_feat] = le.fit_transform(df_data[_feat])\n",
    "    le_list.append(le)\n",
    "    \n",
    "ohe = OneHotEncoder()\n",
    "res = ohe.fit_transform(df_data_le).toarray()\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  1],\n",
       "       [ 0,  0,  0, ...,  0,  1,  0],\n",
       "       ...,\n",
       "       [10,  3,  0, ..., 10,  7,  1],\n",
       "       [10,  3,  0, ..., 10,  8,  0],\n",
       "       [10,  3,  0, ..., 10,  8,  1]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_le = df_data_le.astype(\"uint8\")\n",
    "df_data_le.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kres = res[:10000,:]\n",
    "u_kres = df_data_le.values[:10000,:]\n",
    "BATCH_SIZE = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_batch(num, batch_size):\n",
    "    return math.ceil(num/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~200000\n",
      "[[0 1 1 ... 5 4 5]\n",
      " [1 0 2 ... 4 5 4]\n",
      " [1 2 0 ... 5 4 5]\n",
      " ...\n",
      " [6 5 6 ... 5 6 5]\n",
      " [4 5 5 ... 6 5 6]\n",
      " [5 4 6 ... 5 6 5]]\n",
      "200000~400000\n",
      "[[5 6 4 ... 6 5 6]\n",
      " [6 5 5 ... 5 6 5]\n",
      " [5 6 5 ... 6 5 6]\n",
      " ...\n",
      " [5 4 6 ... 3 4 3]\n",
      " [5 6 4 ... 4 3 4]\n",
      " [6 5 5 ... 3 4 3]]\n",
      "400000~493848\n",
      "[[5 6 5 ... 4 3 4]\n",
      " [6 5 6 ... 3 4 3]\n",
      " [5 6 5 ... 3 3 4]\n",
      " ...\n",
      " [6 5 6 ... 5 6 5]\n",
      " [5 6 5 ... 6 5 6]\n",
      " [6 5 6 ... 5 6 5]]\n"
     ]
    }
   ],
   "source": [
    "def m1(res1, res2):\n",
    "    out1 = manhattan_distances(res1, res2) / 2\n",
    "    return out1.astype(\"uint8\")\n",
    "\n",
    "for i in range(get_max_batch(res.shape[0], BATCH_SIZE)):\n",
    "    st = i * BATCH_SIZE\n",
    "    et = (i+1) * BATCH_SIZE if (i+1) * BATCH_SIZE < res.shape[0] else res.shape[0]\n",
    "    ures = res[st:et,:]\n",
    "    print(f'{st}~{et}')\n",
    "    out1 = m1(ures, kres)\n",
    "    print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15.1\n",
    "del out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~200000\n",
      "[[0 1 1 ... 5 4 5]\n",
      " [1 0 2 ... 4 5 4]\n",
      " [1 2 0 ... 5 4 5]\n",
      " ...\n",
      " [6 5 6 ... 5 6 5]\n",
      " [4 5 5 ... 6 5 6]\n",
      " [5 4 6 ... 5 6 5]]\n",
      "200000~400000\n",
      "[[5 6 4 ... 6 5 6]\n",
      " [6 5 5 ... 5 6 5]\n",
      " [5 6 5 ... 6 5 6]\n",
      " ...\n",
      " [5 4 6 ... 3 4 3]\n",
      " [5 6 4 ... 4 3 4]\n",
      " [6 5 5 ... 3 4 3]]\n",
      "400000~493848\n",
      "[[5 6 5 ... 4 3 4]\n",
      " [6 5 6 ... 3 4 3]\n",
      " [5 6 5 ... 3 3 4]\n",
      " ...\n",
      " [6 5 6 ... 5 6 5]\n",
      " [5 6 5 ... 6 5 6]\n",
      " [6 5 6 ... 5 6 5]]\n"
     ]
    }
   ],
   "source": [
    "def m2(res1, res2):\n",
    "    out2 = pairwise_distances(res1, res2, metric=\"hamming\") * res1.shape[1]\n",
    "    return out2.astype(\"uint8\")\n",
    "\n",
    "for i in range(get_max_batch(res.shape[0], BATCH_SIZE)):\n",
    "    st = i * BATCH_SIZE\n",
    "    et = (i+1) * BATCH_SIZE if (i+1) * BATCH_SIZE < res.shape[0] else res.shape[0]\n",
    "    u_ures = df_data_le.values[st:et,:]\n",
    "    print(f'{st}~{et}')\n",
    "    out2 = m2(u_ures, u_kres)\n",
    "    print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15.1\n",
    "del out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHL_Z790\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:1020: UserWarning: Could not adhere to working_memory config. Currently 0MiB, 1MiB required.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 ... 5 4 5]\n",
      " [1 0 2 ... 4 5 4]\n",
      " [1 2 0 ... 5 4 5]\n",
      " ...\n",
      " [6 5 6 ... 5 6 5]\n",
      " [4 5 5 ... 6 5 6]\n",
      " [5 4 6 ... 5 6 5]]\n",
      "200000~400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHL_Z790\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:1020: UserWarning: Could not adhere to working_memory config. Currently 0MiB, 1MiB required.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 6 4 ... 6 5 6]\n",
      " [6 5 5 ... 5 6 5]\n",
      " [5 6 5 ... 6 5 6]\n",
      " ...\n",
      " [5 4 6 ... 3 4 3]\n",
      " [5 6 4 ... 4 3 4]\n",
      " [6 5 5 ... 3 4 3]]\n",
      "400000~493848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHL_Z790\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:1020: UserWarning: Could not adhere to working_memory config. Currently 0MiB, 1MiB required.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 6 5 ... 4 3 4]\n",
      " [6 5 6 ... 3 4 3]\n",
      " [5 6 5 ... 3 3 4]\n",
      " ...\n",
      " [6 5 6 ... 5 6 5]\n",
      " [5 6 5 ... 6 5 6]\n",
      " [6 5 6 ... 5 6 5]]\n"
     ]
    }
   ],
   "source": [
    "def m2c(res1, res2):\n",
    "    out = np.empty((res1.shape[0], res2.shape[0]), dtype=\"uint8\")\n",
    "    col = 0\n",
    "    for _m in pairwise_distances_chunked(res1, res2, metric=\"hamming\", working_memory=0):\n",
    "        out[col:col+len(_m)] = (_m * res1.shape[1])\n",
    "        col += len(_m)\n",
    "    return out.astype(\"uint8\")\n",
    "\n",
    "\n",
    "for i in range(get_max_batch(res.shape[0], BATCH_SIZE)):\n",
    "    st = i * BATCH_SIZE\n",
    "    et = (i+1) * BATCH_SIZE if (i+1) * BATCH_SIZE < res.shape[0] else res.shape[0]\n",
    "    u_ures = df_data_le.values[st:et,:]\n",
    "    print(f'{st}~{et}')\n",
    "    out2c = m2c(u_ures, u_kres)\n",
    "    print(out2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15.1\n",
    "del out2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~200000\n",
      "[[0 1 1 ... 5 4 5]\n",
      " [1 0 2 ... 4 5 4]\n",
      " [1 2 0 ... 5 4 5]\n",
      " ...\n",
      " [6 5 6 ... 5 6 5]\n",
      " [4 5 5 ... 6 5 6]\n",
      " [5 4 6 ... 5 6 5]]\n",
      "200000~400000\n",
      "[[5 6 4 ... 6 5 6]\n",
      " [6 5 5 ... 5 6 5]\n",
      " [5 6 5 ... 6 5 6]\n",
      " ...\n",
      " [5 4 6 ... 3 4 3]\n",
      " [5 6 4 ... 4 3 4]\n",
      " [6 5 5 ... 3 4 3]]\n",
      "400000~493848\n",
      "[[5 6 5 ... 4 3 4]\n",
      " [6 5 6 ... 3 4 3]\n",
      " [5 6 5 ... 3 3 4]\n",
      " ...\n",
      " [6 5 6 ... 5 6 5]\n",
      " [5 6 5 ... 6 5 6]\n",
      " [6 5 6 ... 5 6 5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import DistanceMetric\n",
    "def m3(res1, res2):\n",
    "    out3 = DistanceMetric.get_metric('hamming').pairwise(res1, res2) * res2.shape[1]\n",
    "    return out3.astype(\"uint8\")\n",
    "\n",
    "for i in range(get_max_batch(res.shape[0], BATCH_SIZE)):\n",
    "    st = i * BATCH_SIZE\n",
    "    et = (i+1) * BATCH_SIZE if (i+1) * BATCH_SIZE < res.shape[0] else res.shape[0]\n",
    "    u_ures = df_data_le.values[st:et,:]\n",
    "    print(f'{st}~{et}')\n",
    "    out3 = m3(u_ures, u_kres)\n",
    "    print(out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15.1\n",
    "del out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~200000\n",
      "[[0 1 1 ... 5 4 5]\n",
      " [1 0 2 ... 4 5 4]\n",
      " [1 2 0 ... 5 4 5]\n",
      " ...\n",
      " [6 5 6 ... 5 6 5]\n",
      " [4 5 5 ... 6 5 6]\n",
      " [5 4 6 ... 5 6 5]]\n",
      "200000~400000\n",
      "[[5 6 4 ... 6 5 6]\n",
      " [6 5 5 ... 5 6 5]\n",
      " [5 6 5 ... 6 5 6]\n",
      " ...\n",
      " [5 4 6 ... 3 4 3]\n",
      " [5 6 4 ... 4 3 4]\n",
      " [6 5 5 ... 3 4 3]]\n",
      "400000~493848\n",
      "[[5 6 5 ... 4 3 4]\n",
      " [6 5 6 ... 3 4 3]\n",
      " [5 6 5 ... 3 3 4]\n",
      " ...\n",
      " [6 5 6 ... 5 6 5]\n",
      " [5 6 5 ... 6 5 6]\n",
      " [6 5 6 ... 5 6 5]]\n"
     ]
    }
   ],
   "source": [
    "def m2c(res1, res2):\n",
    "    out = np.empty((res1.shape[0], res2.shape[0]), dtype=\"uint8\")\n",
    "    col = 0\n",
    "    for _m in pairwise_distances_chunked(res1, res2, metric=\"hamming\"):\n",
    "        out[col:col+len(_m)] = _m * res1.shape[1]\n",
    "        col += len(_m)\n",
    "    return out.astype(\"uint8\")\n",
    "\n",
    "for i in range(get_max_batch(res.shape[0], BATCH_SIZE)):\n",
    "    st = i * BATCH_SIZE\n",
    "    et = (i+1) * BATCH_SIZE if (i+1) * BATCH_SIZE < res.shape[0] else res.shape[0]\n",
    "    u_ures = df_data_le.values[st:et,:]\n",
    "    print(f'{st}~{et}')\n",
    "    out2c = m2c(u_ures, u_kres)\n",
    "    print(out2c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf208cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
