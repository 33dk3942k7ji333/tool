{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "N = 1\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(N)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(N)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(N)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(N)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dec063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from threading import Event, Thread\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import v2 as T_v2\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModel, PreTrainedModel, set_seed\n",
    "\n",
    "torch.set_num_threads(N)\n",
    "torch.set_num_interop_threads(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a206ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK\n",
    "TASK_NAME = \"dinov2\"\n",
    "SEED = 47\n",
    "\n",
    "# MONITOR\n",
    "MAIN_PID = os.getpid()\n",
    "MONITOR_INTERVAL = 0.1\n",
    "USAGE_INFO = []\n",
    "CPU_PERCENT_HISTORY = []\n",
    "\n",
    "cnt_cpu = psutil.cpu_count(logical=True)\n",
    "assert cnt_cpu is not None\n",
    "NUM_CPUS = int(cnt_cpu)\n",
    "\n",
    "# MODEL\n",
    "MODEL_PATH = \"./model/dinov2_small\"\n",
    "DATASET_PATH = \"./dataset/mini_imagenet\"\n",
    "MODEL_DIM = 384\n",
    "NUM_CLASS = 100\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Tensorboard\n",
    "LOG_DIR = f\"./runs/{TASK_NAME}_\" + datetime.datetime.now().strftime(\"%m%d%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26547e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s)\")\n",
    "\n",
    "file_handler = logging.FileHandler(f\"{TASK_NAME}.log\", encoding=\"utf-8\")\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor\n",
    "def get_process_group_usage(pid: int):\n",
    "    total_mem = 0\n",
    "    total_proc_cnt = 0\n",
    "    all_cpu_affinity = set()\n",
    "\n",
    "    try:\n",
    "        main_proc = psutil.Process(pid)\n",
    "        all_proc = [main_proc] + main_proc.children(recursive=True)\n",
    "        total_proc_cnt = len(all_proc)\n",
    "\n",
    "        for p in all_proc:\n",
    "            try:\n",
    "                if p.is_running():\n",
    "                    cpu_affinity = p.cpu_affinity()\n",
    "                    if cpu_affinity is not None:\n",
    "                        all_cpu_affinity.update(cpu_affinity)\n",
    "                total_mem += p.memory_info().rss\n",
    "            except psutil.NoSuchProcess:\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Get Process Info Failed: {e}\", exc_info=True)\n",
    "\n",
    "    return {\n",
    "        \"memory_gb\": total_mem / (1024**3),\n",
    "        \"process_count\": total_proc_cnt,\n",
    "        \"affinity_cores\": sorted(list(all_cpu_affinity)),\n",
    "    }\n",
    "\n",
    "\n",
    "def monitor_usage(interval_sec: float, stop_event: Event):\n",
    "    try:\n",
    "        # Priming\n",
    "        psutil.Process(MAIN_PID).cpu_percent()\n",
    "        psutil.cpu_percent(percpu=True)\n",
    "        time.sleep(0.1)\n",
    "    except psutil.NoSuchProcess:\n",
    "        logger.error(\"Process Not Found\", exc_info=True)\n",
    "        return\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        cur_time = time.time()\n",
    "        usage_data = get_process_group_usage(MAIN_PID)\n",
    "        cpu_percent = psutil.cpu_percent(percpu=True)\n",
    "\n",
    "        USAGE_INFO.append({\"time\": cur_time, **usage_data})\n",
    "        CPU_PERCENT_HISTORY.append(cpu_percent)\n",
    "\n",
    "        time.sleep(interval_sec)\n",
    "\n",
    "\n",
    "def get_vm_total_memory():\n",
    "    mem_info = psutil.virtual_memory()\n",
    "    total_gb = mem_info.total / (1024**3)\n",
    "    return total_gb\n",
    "\n",
    "\n",
    "ALLOC_MEM = get_vm_total_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "def set_all_seeds(seed: int):\n",
    "    set_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_all_seeds(SEED)\n",
    "tb_writer = SummaryWriter(LOG_DIR)\n",
    "\n",
    "# Start Monitor\n",
    "stop_monitor_event = Event()\n",
    "monitor_thread = Thread(target=monitor_usage, args=(MONITOR_INTERVAL, stop_monitor_event))\n",
    "monitor_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ede8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class MiniImageNetDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, split: str, transform: Optional[T_v2.Compose] = None):\n",
    "        self.root_dir = Path(root_dir) / split\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_idx = {}\n",
    "\n",
    "        for i, class_path in enumerate(sorted(self.root_dir.iterdir())):\n",
    "            if class_path.is_dir():\n",
    "                class_name = class_path.name\n",
    "                self.class_idx[class_name] = i\n",
    "                image_files = list(class_path.glob(\"*.JPEG\"))\n",
    "                for img_path in image_files:\n",
    "                    self.labels.append(i)\n",
    "                    self.image_paths.append(img_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        image = Image.open(str(img_path)).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return {\"image\": image, \"label\": label}\n",
    "\n",
    "\n",
    "def get_train_transforms():\n",
    "    transforms_list = [\n",
    "        # RandomFlip\n",
    "        T_v2.RandomHorizontalFlip(p=0.5),\n",
    "        T_v2.RandomVerticalFlip(p=0.0),\n",
    "        # random_rotate\n",
    "        T_v2.RandomChoice(\n",
    "            [\n",
    "                T_v2.RandomRotation([0, 0]),\n",
    "                T_v2.RandomRotation([90, 90]),\n",
    "                T_v2.RandomRotation([180, 180]),\n",
    "                T_v2.RandomRotation([270, 270]),\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    return T_v2.Compose(transforms_list)\n",
    "\n",
    "\n",
    "class ImageCollate:\n",
    "    def __init__(self, processor: AutoImageProcessor):\n",
    "        self.processor = processor\n",
    "\n",
    "    def __call__(self, batch: list[dict]):\n",
    "        images = [item[\"image\"] for item in batch]\n",
    "        labels = [item[\"label\"] for item in batch]\n",
    "\n",
    "        encoding = self.processor(images, return_tensors=\"pt\")  # type: ignore\n",
    "\n",
    "        batch_labels = torch.stack(labels)\n",
    "\n",
    "        result_batch = {\n",
    "            \"pixel_values\": encoding[\"pixel_values\"],\n",
    "            \"labels\": batch_labels,\n",
    "        }\n",
    "\n",
    "        return result_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd30d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Backbone\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_PATH)\n",
    "model_backbone = AutoModel.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Create Dataset\n",
    "train_dataset = MiniImageNetDataset(DATASET_PATH, split=\"train\", transform=get_train_transforms())\n",
    "val_dataset = MiniImageNetDataset(DATASET_PATH, split=\"test\")\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=ImageCollate(processor),\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=ImageCollate(processor),\n",
    ")\n",
    "\n",
    "logger.info(f\"Training Data: {len(train_dataset):>7d} ({len(train_dataset.class_idx):>4d} class)\")\n",
    "logger.info(f\" Testing Data: {len(val_dataset):>7d} ({len(val_dataset.class_idx):>4d} class)\")\n",
    "logger.info(f\"       Resize: {processor.size}\")\n",
    "logger.info(f\"    Crop_size: {processor.crop_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbd80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class DINOv2LinearClassifier(nn.Module):\n",
    "    def __init__(self, dinov2_model: PreTrainedModel, embed_dim: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.dinov2 = dinov2_model\n",
    "        for param in self.dinov2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, pixel_values: torch.Tensor):\n",
    "        outputs = self.dinov2(pixel_values, output_hidden_states=False)\n",
    "        cls_token_output = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        logits = self.classifier(cls_token_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57afaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "model = DINOv2LinearClassifier(model_backbone, MODEL_DIM, NUM_CLASS)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=LEARNING_RATE, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.modules.loss._Loss,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    step: int,\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_correct = 0\n",
    "    num_data = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"TRAIN\"):\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(pixel_values)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        correct = (predicted == labels).sum()\n",
    "        num_correct += correct.item()\n",
    "        step_acc = correct / labels.size(0)\n",
    "\n",
    "        tb_writer.add_scalar(\"Train/step_loss\", loss.item(), step)\n",
    "        tb_writer.add_scalar(\"Train/step_accuracy\", step_acc, step)\n",
    "\n",
    "        num_data += labels.size(0)\n",
    "        step += 1\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = 100 * num_correct / num_data\n",
    "    tb_writer.add_scalar(\"Train/loss\", avg_loss, epoch)\n",
    "    tb_writer.add_scalar(\"Train/accuracy\", accuracy, epoch)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "# Test\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.modules.loss._Loss,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_correct = 0\n",
    "    num_data = 0\n",
    "    st = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"TEST\"):\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(pixel_values)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            num_data += labels.size(0)\n",
    "            num_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = 100 * num_correct / num_data\n",
    "    elapsed_time = time.time() - st\n",
    "\n",
    "    tb_writer.add_scalar(\"Test/loss\", avg_loss, epoch)\n",
    "    tb_writer.add_scalar(\"Test/accuracy\", accuracy, epoch)\n",
    "    tb_writer.add_scalar(\"Test/time\", elapsed_time, epoch)\n",
    "    return avg_loss, accuracy, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee84465",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_time = []\n",
    "step = 0\n",
    "model.to(DEVICE)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE, epoch, step)\n",
    "    val_loss, val_acc, elapsed_time = evaluate(model, val_loader, criterion, DEVICE, epoch)\n",
    "    lst_time.append(elapsed_time)\n",
    "\n",
    "    logger.info(\n",
    "        f\"[{epoch:>3d}/{NUM_EPOCHS:>3d}] - Train Acc: {train_acc:.2f}%, Train Loss: {train_loss:.2f}, Test Acc: {val_acc:.2f}%, Test Loss: {val_loss:.2f}\"\n",
    "    )\n",
    "\n",
    "stop_monitor_event.set()\n",
    "logger.info(f\"Inference Average Cost Time: {sum(lst_time) / len(lst_time):.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371fa8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_forward(data_list, window_size=9):\n",
    "    N = len(data_list)\n",
    "    new_list = []\n",
    "\n",
    "    for i in range(N):\n",
    "        start_index = max(0, i - window_size)\n",
    "        window = data_list[start_index : i + 1]\n",
    "        average = sum(window) / len(window) if window else 0\n",
    "        new_list.append(average)\n",
    "\n",
    "    return new_list\n",
    "\n",
    "\n",
    "if USAGE_INFO:\n",
    "    df = pd.DataFrame.from_records(USAGE_INFO)\n",
    "    ELAPSED_TIME = df[\"time\"] - df[\"time\"].min()\n",
    "    MEM_USAGE = df[\"memory_gb\"]\n",
    "    cpu_matrix = np.array(CPU_PERCENT_HISTORY)\n",
    "\n",
    "    cpu_usage = []\n",
    "    for i in cpu_matrix:\n",
    "        result = [v for v in i if v > 0.5]\n",
    "        cpu_usage.append(sum(result) / 100)\n",
    "\n",
    "    cpu_usage = moving_average_forward(cpu_usage)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, sharex=True, figsize=(15, 12))\n",
    "    ax1, ax2, ax3 = axes\n",
    "\n",
    "    # CPU Heapmap\n",
    "    im = ax1.imshow(\n",
    "        cpu_matrix.T,\n",
    "        aspect=\"auto\",\n",
    "        interpolation=\"none\",\n",
    "        norm=mcolors.Normalize(vmin=0, vmax=100),\n",
    "        extent=[ELAPSED_TIME.min(), ELAPSED_TIME.max(), NUM_CPUS - 0.5, -0.5],\n",
    "    )\n",
    "    ax1.set_title(\"CPU Usage (Logical Cores)\")\n",
    "    ax1.set_ylabel(\"Core Index\")\n",
    "    fig.colorbar(im, ax=ax1, orientation=\"vertical\", label=\"CPU Usage (%)\")\n",
    "\n",
    "    # CPU Usage\n",
    "    ax2.plot(ELAPSED_TIME, cpu_usage, label=\"CPU Usage\", color=\"tab:blue\")\n",
    "    ax2.axhline(\n",
    "        max(cpu_usage),\n",
    "        color=\"r\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=0.5,\n",
    "        label=f\"CPU Usage Peak: {max(cpu_usage):.2f} Cores\",\n",
    "    )\n",
    "    ax2.set_title(f\"Total CPU Usage (Max CPUs: {NUM_CPUS})\")\n",
    "    ax2.set_ylabel(\"CPU Cores\")\n",
    "    ax2.set_ylim(0, NUM_CPUS)\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax2.grid(True, axis=\"y\")\n",
    "\n",
    "    # Memory Usage\n",
    "    ax3.plot(ELAPSED_TIME, MEM_USAGE, label=\"Memory Usage\", color=\"tab:red\")\n",
    "    ax3.axhline(\n",
    "        max(MEM_USAGE),\n",
    "        color=\"r\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=0.5,\n",
    "        label=f\"Memory Usage Peak: {max(MEM_USAGE):.2f} GB\",\n",
    "    )\n",
    "    ax3.set_title(\"Memory Usage (RSS)\")\n",
    "    ax3.set_xlabel(\"Time (sec)\")\n",
    "    ax3.set_ylabel(\"Memory Usage (GB)\")\n",
    "    ax3.set_ylim(0, ALLOC_MEM)\n",
    "    ax3.legend(loc=\"upper right\")\n",
    "    ax3.grid(True, axis=\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f103a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"model_weights.pth\"\n",
    "torch.save(model, PATH)\n",
    "model2 = torch.load(\"model_weights.pth\", weights_only=False)\n",
    "\n",
    "for k, v in model2.state_dict().items():\n",
    "    print(f\"{k:>25s}: {v.size()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
