{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import my_logger\n",
    "\n",
    "logging.config.dictConfig(my_logger.dic_log_cfg)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gen_data\n",
    "# gen_data.gen_data(2000, 2000, \"Test_Stage_firstlot\")\n",
    "# gen_data.gen_data(1200, 1200, \"Test_Stage_exist\")\n",
    "gen_data.gen_data(1000, 500, \"Test_Stage/result\")\n",
    "gen_data.gen_data(1500, 500, \"Test_Stage_test_cover/result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting\n",
    "STAGE = \"Test_Stage\"\n",
    "LAYER = \"Test_Layer\"\n",
    "CODE_NAME = \"Test_Cover\"\n",
    "\n",
    "TRAINING_DATA = \"training_data.csv\"\n",
    "TESTING_DATA = \"testing_data.csv\"\n",
    "_TIME = \"_time\"\n",
    "DATE = \"2024/07/01 00:00:00\"\n",
    "\n",
    "fix_cols = [\"Part\", \"Tool\", \"Prev1Tool\"]\n",
    "soc_part_cols = [\"value\\n1\", \"value\\n2\", \"value\\n3\"]\n",
    "\n",
    "lst_soc_ratio = [1, 1, 150, 150, 150, 150, 15, 15, 15, 15]\n",
    "lst_soc_spec = [2, 2, 0.015, 0.015, 0.015, 0.015, 0.15, 0.15, 0.15, 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "_concat = lambda x: \"_\".join(x)\n",
    "\n",
    "def _check_dir(stage: str, code_name: str):\n",
    "    old_dir_name = f'{stage}/result'\n",
    "    new_dir_name = f'{stage}_{code_name}/result'\n",
    "    if not pathlib.Path(old_dir_name).is_dir():\n",
    "        raise LookupError(f'Folder {old_dir_name} not found')\n",
    "    if not pathlib.Path(new_dir_name).is_dir():\n",
    "        raise LookupError(f'Folder {new_dir_name} not found')\n",
    "    logger.debug(\"Check Folder OK\")\n",
    "\n",
    "def _check_runtable(stage: str, code_name: str):\n",
    "    old_run_name = f'{stage}/result/runtable_0.csv'\n",
    "    new_run_name = f'{stage}_{code_name}/result/runtable_0.csv'\n",
    "    if not pathlib.Path(old_run_name).is_file():\n",
    "        raise LookupError(f'File {old_run_name} not found')\n",
    "    if not pathlib.Path(new_run_name).is_file():\n",
    "        raise LookupError(f'File {new_run_name} not found')\n",
    "    logger.debug(\"Check Runtable OK\")\n",
    "    \n",
    "def _check_file(training_data: str, testint_data: str):\n",
    "    if not pathlib.Path(training_data).is_file():\n",
    "        raise LookupError(f'File {training_data} not found')\n",
    "    if not pathlib.Path(testint_data).is_file():\n",
    "        raise LookupError(f'File {testint_data} not found')\n",
    "    logger.debug(\"Check File OK\")\n",
    "\n",
    "def check_file(param: dict):\n",
    "    _check_dir(param[\"STAGE\"], param[\"CODE_NAME\"])\n",
    "    _check_runtable(param[\"STAGE\"], param[\"CODE_NAME\"])\n",
    "    _check_file(param[\"TRAINING_DATA\"], param[\"TESTING_DATA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _concat_csv(lst_file: list, dir_name: str) ->pd.DataFrame:\n",
    "    df_res = pd.DataFrame()\n",
    "    for _file in lst_file:\n",
    "        df_file = pd.read_csv(f'{dir_name}/{_file}')\n",
    "        df_res = pd.concat([df_res, df_file])\n",
    "    logger.info(f'Total {df_res.shape[0]} runtable in {dir_name}')\n",
    "    return df_res\n",
    "\n",
    "def _get_file_list(dir_name: str, file_type: str) -> list:\n",
    "    chk_run = re.compile(\"runtable_\\d+.csv\")\n",
    "    lst_file = [str(_file.name) for _file in list(pathlib.Path(dir_name).glob(f'*.{file_type}'))]\n",
    "    lst_res = [_file for _file in lst_file if chk_run.match(_file)]\n",
    "    logger.info(f'Found {len(lst_res)} csv in {dir_name}')\n",
    "    return lst_res\n",
    "\n",
    "def concat_run(param: dict):\n",
    "    os.makedirs(\"_data\", exist_ok=True)\n",
    "    stage, code_name = param[\"STAGE\"], param[\"CODE_NAME\"]\n",
    "    old_dir = f'{stage}/result'\n",
    "    new_dir = f'{stage}_{code_name}/result'\n",
    "    lst_old_file = _get_file_list(old_dir , \"csv\")\n",
    "    lst_new_file = _get_file_list(new_dir , \"csv\")\n",
    "    df_old_run = _concat_csv(lst_old_file, old_dir)\n",
    "    df_new_run = _concat_csv(lst_new_file, new_dir)\n",
    "    df_old_run.to_csv(f'_data/{stage}_run.csv', index=False)\n",
    "    df_new_run.to_csv(f'_data/{stage}_{code_name}_run.csv', index=False)\n",
    "    return df_old_run, df_new_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_run_diff(df_old_run, df_new_run, soc_part_cols, lst_soc_ratio):\n",
    "    suffix = [\"_old\", \"_new\"]\n",
    "    _df = pd.merge(df_old_run, df_new_run, how='inner',  on=fix_cols, suffixes=suffix)\n",
    "    \n",
    "    for col, _ratio in zip(soc_part_cols, lst_soc_ratio):\n",
    "        _col = col.replace(\"\\n\", \" \")\n",
    "        _df[col+\"diff\"] = _df[col+suffix[0]] - _df[col+suffix[1]]\n",
    "        _df[col+\"mae\"] = abs(_df[col+\"diff\"])\n",
    "        _mae = _df[col+\"mae\"].mean()\n",
    "        logger.debug(f'{_col} MAE: {_mae:.6f}, in nm: {_mae*_ratio:.6f}')\n",
    "        \n",
    "def validation_ocap(df, lst_soc_spec):\n",
    "    _ocap = False\n",
    "    for col, spec in zip(soc_part_cols, lst_soc_spec):\n",
    "        if abs(df[f'{col}_Rn'] - df[f'{col}_ML']) > spec:\n",
    "            _ocap = True\n",
    "    return _ocap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:51:55 [D][636599369.py][_check_dir:  10] Check Folder OK\n",
      "2024-07-22 00:51:55 [D][636599369.py][_check_runtable:  19] Check Runtable OK\n",
      "2024-07-22 00:51:55 [D][636599369.py][_check_file:  26] Check File OK\n",
      "2024-07-22 00:51:55 [I][1200119199.py][_get_file_list:  13] Found 2 csv in Test_Stage/result\n",
      "2024-07-22 00:51:55 [I][1200119199.py][_get_file_list:  13] Found 3 csv in Test_Stage_Test_Cover/result\n",
      "2024-07-22 00:51:55 [I][1200119199.py][_concat_csv:   6] Total 1000 runtable in Test_Stage/result\n",
      "2024-07-22 00:51:55 [I][1200119199.py][_concat_csv:   6] Total 1500 runtable in Test_Stage_Test_Cover/result\n",
      "2024-07-22 00:51:55 [I][947676554.py][  <module>:  16] Training Data: (959, 7)\n",
      "2024-07-22 00:51:55 [I][947676554.py][  <module>:  17] Testing Data: (2000, 7)\n",
      "2024-07-22 00:51:55 [I][947676554.py][  <module>:  18] Old Runtable: (1000, 7)\n",
      "2024-07-22 00:51:55 [I][947676554.py][  <module>:  19] New Runtable: (1500, 7)\n",
      "2024-07-22 00:51:55 [D][1515922192.py][cal_run_diff:  10] value 1 MAE: 5.736170, in nm: 5.736170\n",
      "2024-07-22 00:51:55 [D][1515922192.py][cal_run_diff:  10] value 2 MAE: 1.065426, in nm: 1.065426\n",
      "2024-07-22 00:51:55 [D][1515922192.py][cal_run_diff:  10] value 3 MAE: 0.007678, in nm: 1.151729\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    \"STAGE\": STAGE, \n",
    "    \"LAYER\": LAYER,\n",
    "    \"CODE_NAME\": CODE_NAME,\n",
    "    \"TRAINING_DATA\": TRAINING_DATA,\n",
    "    \"TESTING_DATA\": TESTING_DATA,\n",
    "    }\n",
    "\n",
    "\n",
    "check_file(param)\n",
    "df_train = pd.read_csv(f'./{TRAINING_DATA}')\n",
    "df_test = pd.read_csv(f'./{TESTING_DATA}')\n",
    "df_old_run, df_new_run = concat_run(param)\n",
    "df_old_run.loc[:, \"COMB\"] = df_old_run[fix_cols].apply(_concat, axis=1)\n",
    "df_new_run.loc[:, \"COMB\"] = df_new_run[fix_cols].apply(_concat, axis=1)\n",
    "logger.info(f'Training Data: {df_train.shape}')\n",
    "logger.info(f'Testing Data: {df_test.shape}')\n",
    "logger.info(f'Old Runtable: {df_old_run.shape}')\n",
    "logger.info(f'New Runtable: {df_new_run.shape}')\n",
    "\n",
    "cal_run_diff(df_old_run, df_new_run, soc_part_cols, lst_soc_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:51:55 [I][946419373.py][  <module>:  13] df_train: (959, 7), with 901 runtable\n",
      "2024-07-22 00:51:55 [I][946419373.py][  <module>:  14] df_test_before: (959, 7), with 897 runtable\n",
      "2024-07-22 00:51:55 [I][946419373.py][  <module>:  15] df_test_after: (1041, 7), with 983 runtable\n",
      "C:\\Users\\CHL_Z790\\AppData\\Local\\Temp\\ipykernel_34440\\946419373.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_after_comb[\"COMB\"] = df_test_after_comb[fix_cols].apply(_concat, axis=1)\n",
      "2024-07-22 00:51:55 [I][946419373.py][  <module>:  26] df_firstlot: (216, 8)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Training/Testing Data\n",
    "df_test[_TIME] = pd.to_datetime(df_test[_TIME])\n",
    "df_test = df_test.sort_values(by=_TIME, ascending=True)\n",
    "cond_before_date = df_test[_TIME] < pd.to_datetime(DATE)\n",
    "\n",
    "df_test_before = df_test[cond_before_date]\n",
    "df_test_after = df_test[~cond_before_date]\n",
    "\n",
    "df_train_comb = df_train.drop_duplicates(subset=fix_cols, keep=\"first\")\n",
    "df_test_before_comb = df_test_before.drop_duplicates(subset=fix_cols, keep=\"first\")\n",
    "df_test_after_comb = df_test_after.drop_duplicates(subset=fix_cols, keep=\"first\")\n",
    "\n",
    "logger.info(f'df_train: {df_train.shape}, with {df_train_comb.shape[0]} runtable')\n",
    "logger.info(f'df_test_before: {df_test_before.shape}, with {df_test_before_comb.shape[0]} runtable')\n",
    "logger.info(f'df_test_after: {df_test_after.shape}, with {df_test_after_comb.shape[0]} runtable')\n",
    "\n",
    "# Runtable in Training Data and Testing Data\n",
    "lst_known_run = list(df_train_comb[fix_cols].apply(_concat, axis=1))\n",
    "lst_known_run.extend(list(df_test_before_comb[fix_cols].apply(_concat, axis=1)))\n",
    "lst_known_run = list(set(lst_known_run))\n",
    "\n",
    "# FirstLot Runtable \n",
    "df_test_after_comb[\"COMB\"] = df_test_after_comb[fix_cols].apply(_concat, axis=1)\n",
    "cond_firstlot = df_test_after_comb[\"COMB\"].isin(lst_known_run)\n",
    "df_firstlot = df_test_after_comb[cond_firstlot]\n",
    "logger.info(f'df_firstlot: {df_firstlot.shape}')\n",
    "\n",
    "# Compute Result\n",
    "df_old_result = pd.merge(df_firstlot, df_old_run, how=\"inner\", on=fix_cols, suffixes=[\"_Rn\", \"_ML\"])\n",
    "df_new_result = pd.merge(df_firstlot, df_new_run, how=\"inner\", on=fix_cols, suffixes=[\"_Rn\", \"_ML\"])\n",
    "\n",
    "df_old_result[\"OCAP\"] = df_old_result.apply(validation_ocap, args=(lst_soc_spec,) ,axis=1)\n",
    "df_new_result[\"OCAP\"] = df_new_result.apply(validation_ocap, args=(lst_soc_spec,) ,axis=1)\n",
    "\n",
    "cond_old_success = df_old_result[\"OCAP\"] == False\n",
    "cond_new_success = df_new_result[\"OCAP\"] == False\n",
    "\n",
    "old_cr = 100 * df_old_result.shape[0] / df_firstlot.shape[0]\n",
    "new_cr = 100 * df_new_result.shape[0] / df_firstlot.shape[0]\n",
    "old_sr = 100 * df_old_result[cond_old_success].shape[0] / df_old_result.shape[0]\n",
    "new_sr = 100 * df_new_result[cond_new_success].shape[0] / df_new_result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:51:55 [I][1222453530.py][  <module>:   1] Coverage Rate\n",
      "2024-07-22 00:51:55 [I][1222453530.py][  <module>:   2] Old Coverage Rate: 15.74% [34/216]\n",
      "2024-07-22 00:51:55 [I][1222453530.py][  <module>:   3] New Coverage Rate: 15.28% [33/216]\n",
      "2024-07-22 00:51:55 [I][1222453530.py][  <module>:   5] Success Rate\n",
      "2024-07-22 00:51:55 [I][1222453530.py][  <module>:   6] Old Success Rate: 26.47% [9/34]\n",
      "2024-07-22 00:51:55 [I][1222453530.py][  <module>:   7] New Success Rate: 12.12% [4/33]\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Coverage Rate\")\n",
    "logger.info(f'Old Coverage Rate: {old_cr:.2f}% [{df_old_result.shape[0]}/{df_firstlot.shape[0]}]')\n",
    "logger.info(f'New Coverage Rate: {new_cr:.2f}% [{df_new_result.shape[0]}/{df_firstlot.shape[0]}]')\n",
    "\n",
    "logger.info(\"Success Rate\")\n",
    "logger.info(f'Old Success Rate: {old_sr:.2f}% [{df_old_result[cond_old_success].shape[0]}/{df_old_result.shape[0]}]')\n",
    "logger.info(f'New Success Rate: {new_sr:.2f}% [{df_new_result[cond_new_success].shape[0]}/{df_new_result.shape[0]}]')\n",
    "\n",
    "dic_result = {\n",
    "    \"Success\": [df_old_result[cond_old_success].shape[0], df_new_result[cond_new_success].shape[0]],\n",
    "    \"Total\": [df_old_result.shape[0], df_new_result.shape[0]],\n",
    "    \"Success Rate\": [old_sr, new_sr],\n",
    "    \"Coverage Rate\": [old_cr, new_cr],\n",
    "}\n",
    "pd.DataFrame(dic_result, index=[\"old\", param[\"CODE_NAME\"]]).to_csv(\"./result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
